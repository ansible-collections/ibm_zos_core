#!/usr/bin/python
# -*- coding: utf-8 -*-
# Copyright (c) IBM Corporation 2019, 2020
# Apache License, Version 2.0 (see https://opensource.org/licenses/Apache-2.0)

from __future__ import (absolute_import, division, print_function)
__metaclass__ = type

ANSIBLE_METADATA = {'metadata_version': '1.1',
                    'status': ['stableinterface'],
                    'supported_by': 'community'}

DOCUMENTATION = r'''
---
module: zos_copy
version_added: '2.9'
short_description: Copy data to z/OS
description:
  - The C(zos_copy) module copies a file or data set from a local or a
    remote machine to a location on the remote machine.
  - Use the C(zos_fetch) module to copy files or data sets from remote
    locations to local machine.
author: "Asif Mahmud (@asifmahmud)"
options:
  src:
    description:
      - Absolute local path to a file to copy to the remote z/OS system.
      - If C(remote_src) is true, then src must be the absolute path to a USS
        file, name of a data set or data set member.
      - If C(src) is a directory, destination must be a partitioned data set or
        a directory.
      - If C(src) a file and dest ends with "/" or destination is a directory, the
        file is copied to the directory with the same filename as src.
      - If C(src) is a VSAM data set, destination must also be a VSAM.
      - Required unless using C(content).
    type: str
  dest:
    description:
      - Remote absolute path or data set where the file should be copied to.
      - Destination can be a USS location separated with ‘/' or MVS data set
        separated with ‘.’.
      - If C(src) is a directory, this must be a partitioned data set.
      - If C(dest) is a nonexistent path, it will be created.
      - If C(dest) is a nonexistent data set, it will be allocated.
      - If C(src) and C(dest) are files and if the parent directory of C(dest)
        doesn't exist, then the task will fail.
      - When the C(dest) is VSAM(KSDS) or VSAM(ESDS), then source can be ESDS, 
        KSDS or RRDS.
      - When the C(dest) is VSAM(RRDS), then the source must be RRDS.
      - When C(dest) is VSAM(LDS), then source must be LDS.
    type: str
    required: true
  content:
    description:
      - When used instead of C(src), sets the contents of a file or data set
        directly to the specified value.
      - Works only when C(dest) is a USS file, sequential data set or a
        partitioned data set member.
      - This is for simple values, for anything complex or with formatting, the
        M(template) module should be used.
    type: str
    required: false
  backup:
    description:
      - Specifies whether a backup of destination should be created before
        copying data.
      - When set to C(true), the module creates a backup file or data set.
    type: bool
    default: false
    required: false
  backup_path:
    description:
      - Specify the USS file name or data set name for the dest backup.
      - If the dest is a USS file or path, the backup_path name must be a file
        or path name, and the USS path or file must be an absolute path name.
      - If the dest is an MVS data set, the backup_path name must be an MVS
        data set name.
      - If the backup_path is not provided, the default backup_path name will
        be used. If the dest is a USS file or USS path, the name of the backup
        file will be the destination file or path name appended with a
        timestamp, e.g. C(/path/file_name.2020-04-23-08-32-29-bak.tar).
      - If the dest is an MVS data set, it will be a data set with a random
        name generated by calling ZOAU API, then the MVS backup data set
        recovery can be done by renaming it.
    required: false
  force:
    description:
      - If C(true), the remote file or data set will be overwritten.
      - If C(false), the file or data set will only be copied if the destination
        does not exist.
      - If C(false) and destination exists, the module exits with a note to
        the user.
    type: bool
    default: true
    required: false
  mode:
    description:
      - The permission of the destination file or directory.
      - If C(dest) is USS, this will act as Unix file mode, otherwise ignored.
      - Refer to the M(copy) module for a detailed description of this
        parameter.
    type: str
    required: false
  remote_src:
    description:
      - If C(false), the module will search for src at local machine.
      - If C(true), the module will go to the remote/target machine for the src.
    type: bool
    default: false
    required: false
  local_follow:
    description:
      - This flag indicates that filesystem links in the source tree, if they
        exist, should be followed.
    type: bool
    default: true
    required: false
  is_binary:
    description:
      - If C(true), indicates that the file or data set to be copied is a
        binary file/data set.
    type: bool
    default: false
    required: false
  encoding:
    description:
      - Specifies which encodings the destination file or data set should be
        converted from and to.
      - If this parameter is not provided, no encoding conversions will take
        place.
      - If C(true) and C(src) is an MVS data set, task will fail.
      - Only valid if C(is_binary) is false.
    type: dict
    required: false
    suboptions:
      from:
        description:
          - The encoding to be converted from
        required: true
        type: str
      to:
        description:
          - The encoding to be converted to
        required: true
        type: str
  validate:
    description:
      - Specifies whether to perform checksum validation for source and
        destination files.
      - Valid only for USS destination, otherwise ignored.
    type: bool
    required: false
    default: false
notes:
    - Destination data sets are assumed to be in catalog. When trying to copy
      to an uncataloged data set, the module assumes that the data set does
      not exist and will create it.
    - Destination will be backed up if either C(backup) is C(true) or
      C(backup_path) is provided. If C(backup) is C(false) but C(backup_path)
      is provided, task will fail.
    - When copying local files or directories, temporary storage will be used
      on the remote z/OS system. The size of the temporary storage will
      correspond to the size of the file or directory being copied. Temporary 
      files will always be deleted, regardless of success or failure of the
      copy task.
    - For supported character sets used to encode data, refer to
      U(https://ansible-collections.github.io/ibm_zos_core/supplementary.html#encode)
seealso:
- copy
- fetch
- zos_fetch
- zos_data_set
'''

EXAMPLES = r'''
- name: Copy a local file to a sequential data set
  zos_copy:
    src: /path/to/sample_seq_data_set
    dest: SAMPLE.SEQ.DATA.SET

- name: Copy a local file to a USS location and validate checksum
  zos_copy:
    src: /path/to/test.log
    dest: /tmp/test.log
    validate: true

- name: Copy a local ASCII encoded file and convert to IBM-1047
  zos_copy:
    src: /path/to/file.txt
    dest: /tmp/file.txt
    encoding:
      from: ISO8859-1
      to: IBM-1047

- name: Copy a local directory to a PDSE
  zos_copy:
    src: /path/to/local/dir/
    dest: HLQ.DEST.PDSE

- name: Copy file with permission details
  zos_copy:
    src: /path/to/foo.conf
    dest: /etc/foo.conf
    mode: 0644
    group: foo
    owner: bar

- name: Module will follow the symbolic link specified in src
  zos_copy:
    src: /path/to/link
    dest: /path/to/uss/location
    local_follow: true

- name: Copy a local file to a PDS member
  zos_copy:
    src: /path/to/local/file
    dest: HLQ.SAMPLE.PDSE(MEMBER)

- name: Copy a VSAM(KSDS) to a VSAM(KSDS)
  zos_copy:
    src: SAMPLE.SRC.VSAM
    dest: SAMPLE.DEST.VSAM
    remote_src: true

- name: Copy inline content to a sequential dataset and replace existing data
  zos_copy:
    content: 'Inline content to be copied'
    dest: SAMPLE.SEQ.DATA.SET

- name: Copy a USS file to sequential data set and convert encoding beforehand
  zos_copy:
    src: /path/to/remote/uss/file
    dest: SAMPLE.SEQ.DATA.SET
    remote_src: true
    encoding:
      from: ISO8859-1
      to: IBM-1047

- name: Copy a USS directory to another USS directory
  zos_copy:
    src: /path/to/uss/dir
    dest: /path/to/dest/dir
    remote_src: true

- name: Copy a local binary file to a PDSE member
  zos_copy:
    src: /path/to/binary/file
    dest: HLQ.SAMPLE.PDSE(MEMBER)
    is_binary: true

- name: Copy a sequential data set to a PDS member:
  zos_copy:
    src: SAMPLE.SEQ.DATA.SET
    dest: HLQ.SAMPLE.PDSE(MEMBER)
    remote_src: true

- name: Copy a local file and take a backup of the existing file
  zos_copy:
    src: /path/to/local/file
    dest: /path/to/dest
    backup: true
    backup_path: /tmp/local_file_backup

- name: Copy a PDS on remote system to a new PDS
  zos_copy:
    src: HLQ.SRC.PDS
    dest: HLQ.NEW.PDS
    remote_src: true

- name: Copy a PDS on remote system to a PDS, replacing the original
  zos_copy:
    src: HLQ.SAMPLE.PDSE
    dest: HLQ.EXISTING.PDSE
    remote_src: true

- name: Copy PDS member to a new PDS member. Replace if it already exists
  zos_copy:
    src: HLQ.SAMPLE.PDSE(SRCMEM)
    dest: HLQ.NEW.PDSE(DESTMEM)
    remote_src: true

- name: Copy a USS file to a PDSE member. If PDSE does not exist, allocate it
  zos_copy:
    src: /path/to/uss/src
    dest: DEST.PDSE.DATA.SET(MEMBER)
    remote_src: true

- name: Copy a sequential data set to a USS file
  zos_copy:
    src: SRC.SEQ.DATA.SET
    dest: /tmp/
    remote_src: true

- name: Copy a PDSE member to USS file
  zos_copy:
    src: SRC.PDSE(MEMBER)
    dest: /tmp/member
    remote_src: true

- name: Copy a PDS to a USS directory (/tmp/SRC.PDS).
  zos_copy:
    src: SRC.PDS
    dest: /tmp
    remote_src: true

'''

RETURN = r'''
src:
    description: Source file or data set being copied.
    returned: changed
    type: str
    sample: /path/to/source.log
dest:
    description: Destination file/path or data set name.
    returned: success
    type: str
    sample: SAMPLE.SEQ.DATA.SET
checksum:
    description: SHA256 checksum of the file after running copy.
    returned: C(validate) is C(true) and if dest is USS
    type: str
    sample: 8d320d5f68b048fc97559d771ede68b37a71e8374d1d678d96dcfa2b2da7a64e
backup_path:
    description: Name of the backup file or data set that was created.
    returned: changed and if backup=true
    type: str
    sample: /path/to/file.txt.2015-02-03@04:15~
gid:
    description: Group id of the file, after execution.
    returned: success and if dest is USS
    type: int
    sample: 100
group:
    description: Group of the file, after execution.
    returned: success and if dest is USS
    type: str
    sample: httpd
owner:
    description: Owner of the file, after execution.
    returned: success and if dest is USS
    type: str
    sample: httpd
uid:
    description: Owner id of the file, after execution.
    returned: success and if dest is USS
    type: int
    sample: 100
mode:
    description: Permissions of the target, after execution.
    returned: success and if dest is USS
    type: str
    sample: 0644
size:
    description: Size(in bytes) of the target, after execution.
    returned: success and dest is USS
    type: int
    sample: 1220
state:
    description: State of the target, after execution.
    returned: success and if dest is USS
    type: str
    sample: file
note:
    description: A note to the user after module terminates.
    returned: C(force) is C(false) and dest exists
    type: str
    sample: No data was copied
msg:
    description: Failure message returned by the module.
    returned: failure
    type: str
    sample: Error while gathering data set information
stdout:
    description: The stdout from a USS command or MVS command, if applicable.
    returned: failure
    type: str
    sample: Copying local file /tmp/foo/src to remote path /tmp/foo/dest
stderr:
    description: The stderr of a USS command or MVS command, if applicable.
    returned: failure
    type: str
    sample: FileNotFoundError: No such file or directory '/tmp/foo'
stdout_lines:
    description: List of strings containing individual lines from stdout.
    returned: failure
    type: list
    sample: [u"Copying local file /tmp/foo/src to remote path /tmp/foo/dest.."]
stderr_lines:
    description: List of strings containing individual lines from stderr.
    returned: failure
    type: list
    sample: [u"FileNotFoundError: No such file or directory '/tmp/foo'"]
rc:
    description: The return code of a USS or MVS command, if applicable.
    returned: failure
    type: int
    sample: 8
cmd:
    description: The MVS command issued, if applicable.
    returned: failure
    type: str
    sample: REPRO INDATASET(SAMPLE.DATA.SET) OUTDATASET(SAMPLE.DEST.DATA.SET)
'''

import os
import tempfile
import math
import time
import stat
import shutil

from pathlib import Path
from hashlib import sha256

from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils._text import to_bytes

from ansible_collections.ibm.ibm_zos_core.plugins.module_utils import (
    better_arg_parser,
    data_set,
    encode,
    vtoc,
    backup,
    copy
)

from ansible_collections.ibm.ibm_zos_core.plugins.module_utils.import_handler import (
    MissingZOAUImport
)

try:
    from zoautil_py import Datasets, MVSCmd, types
except Exception:
    Datasets = MissingZOAUImport()
    MVSCmd = MissingZOAUImport()
    types = MissingZOAUImport()


MVS_PARTITIONED = frozenset({'PE', 'PO', 'PDSE', 'PDS'})
MVS_SEQ = frozenset({'PS', 'SEQ'})


class CopyHandler(object):
    def __init__(self, module, dest_exists, is_binary=False):
        """Utility class to handle copying data between two targets

        Arguments:
            module {AnsibleModule} -- The AnsibleModule object from currently running module
            dest_exists {boolean} -- Whether destination already exists

        Keyword Arguments:
            is_binary {bool} -- Whether the file or data set to be copied contains binary data
        """
        self.module = module
        self.dest_exists = dest_exists
        self.is_binary = is_binary

    def fail_json(self, **kwargs):
        """ Wrapper for AnsibleModule.fail_json """
        self.module.fail_json(**kwargs, dest_exists=self.dest_exists)

    def run_command(self, cmd, **kwargs):
        """ Wrapper for AnsibleModule.run_command """
        return self.module.run_command(cmd, **kwargs)

    def copy_to_seq(self, src, temp_path, conv_path, dest, src_ds_type):
        """Copy source to a sequential data set.

        Arguments:
            src {str} -- Path to USS file or data set name
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source file
            dest {str} -- Name of destination data set
            src_ds_type {str} -- The type of source
        """
        src = temp_path or conv_path or src
        try:
            if src_ds_type == 'USS':
                copy.copy_uss2mvs(src, dest, "PS", is_binary=self.is_binary)
            elif src_ds_type in MVS_SEQ.union(MVS_PARTITIONED):
                copy.copy_mvs2mvs(src, dest, is_binary=self.is_binary)
        except Exception as err:
            err = str(err)
            if "I/O abend was trapped" in err:
                try:
                    Datasets.create(dest, "SEQ")
                    copy.copy_mvs2mvs(src, dest, is_binary=self.is_binary)
                except Exception as err:
                    self.fail_json(msg=str(err))
            else:
                self.fail_json(msg=err)

    def copy_to_vsam(self, src, dest):
        """ Copy source VSAM to destination VSAM. If source VSAM exists, then
        it will be deleted and a new VSAM cluster will be allocated.

        Arguments:
            src {str} -- The name of the source VSAM
            dest {str} -- The name of the destination VSAM
        """
        if self.dest_exists:
            rc = Datasets.delete(dest)
            if rc != 0:
                self.fail_json(
                    msg="Unable to delete destination data set {0}".format(dest),
                    rc=rc
                )
        self.allocate_model(dest, src)

        repro_cmd = '''  REPRO -
        INDATASET({0}) -
        OUTDATASET({1})'''.format(src, dest)
        rc, out, err = self._run_mvs_command(
            "IDCAMS", repro_cmd, authorized=True
        )
        if rc != 0:
            self.fail_json(
                msg=("IDCAMS REPRO encountered a problem while "
                     "copying {0} to {1}".format(src, dest)),
                stdout=out, stderr=err, rc=rc,
                stdout_lines=out.splitlines(),
                stderr_lines=err.splitlines(),
                cmd=repro_cmd
            )

    def convert_encoding(self, src, temp_path, encoding):
        """Convert encoding for given src

        Arguments:
            src {str} -- Path to the USS source file or directory
            temp_path {str} -- Path to the location where the control node transferred data to
            encoding {dict} -- Charsets that the source is to be converted from and to

        Raises:
            EncodingConversionError -- When the encoding of a USS file is not able to be converted

        Returns:
            {str} -- The USS path where the converted data is stored
        """
        from_code_set = encoding.get("from")
        to_code_set = encoding.get("to")
        enc_utils = encode.EncodeUtils()
        src = temp_path or src

        if os.path.isdir(src):
            try:
                if not temp_path:
                    temp_dir = tempfile.mkdtemp()
                    shutil.copytree(src, temp_dir)
                    src = temp_dir

                rc, err = enc_utils.uss_convert_encoding_prev(
                    src, src, from_code_set, to_code_set
                )
                if (not rc) or err:
                    raise EncodingConversionError(src, from_code_set, to_code_set)
                self._tag_file_encoding(src, to_code_set, is_dir=True)

            except Exception as err:
                shutil.rmtree(src)
                self.fail_json(msg=str(err))
        else:
            try:
                if not temp_path:
                    fd, temp_src = tempfile.mkstemp()
                    os.close(fd)
                    shutil.copy(src, temp_src)
                    src = temp_src

                rc = enc_utils.uss_convert_encoding(src, src, from_code_set, to_code_set)
                if not rc:
                    raise EncodingConversionError(src, from_code_set, to_code_set)
                self._tag_file_encoding(src, to_code_set)

            except Exception as err:
                os.remove(src)
                self.fail_json(msg=str(err))

        return src

    def backup_data(self, ds_name, ds_type, backup_path):
        """Back up the given data set or file to the location specified by 'backup_path'.
        If 'backup_path' is not specified, then calculate a temporary location
        and copy the file or data set there.

        Arguments:
            ds_name {str} -- Name of the file or data set to be backed up
            ds_type {str} -- Type of the file or data set
            backup_path {str} -- Path to USS location or name of data set
            where data will be backed up

        Returns:
            {str} -- The USS path or data set name where data was backed up
        """
        try:
            if ds_type == "USS":
                return backup.uss_file_backup(ds_name, backup_name=backup_path)
            return backup.mvs_file_backup(ds_name, backup_path)
        except Exception as err:
            self.fail_json(
                msg="Unable to back up destination {0}".format(ds_name),
                stderr=str(err)
            )

    def allocate_model(self, ds_name, model):
        """Use 'model' data sets allocation paramters to allocate the given
        data set.

        Arguments:
            ds_name {str} -- The name of the data set to allocate
            model {str} -- The name of the data set whose allocation parameters
            should be used to allocate 'ds_name'

        Returns:
            {int} -- The return code of executing the allocation command
        """
        alloc_cmd = """  ALLOC -
        DS('{0}') -
        LIKE('{1}')""".format(ds_name, model)
        rc, out, err = self._run_mvs_command("IKJEFT01", alloc_cmd, authorized=True)
        if rc != 0:
            self.fail_json(
                msg="Unable to allocate destination {0}".format(ds_name),
                stdout=out, stderr=err, rc=rc,
                stdout_lines=out.splitlines(),
                stderr_lines=err.splitlines(),
                cmd=alloc_cmd
            )
        return rc

    def _tag_file_encoding(self, file_path, tag, is_dir=False):
        """Tag the file specified by 'file_path' with the given code set.
        If `file_path` is a directory, all of the files and subdirectories will
        be tagged recursively.

        Arguments:
            file_path {str} -- Absolute file path
            tag {str} -- Specifies which code set to tag the file

        Keyword Arguments:
            is_dir {bool} -- Whether 'file_path' specifies a directory. (Default {False})

        """
        rc, out, err = self.run_command("chtag -{0}c {1} {2}".format(
                "R" if is_dir else "t", tag, file_path
            )
        )
        if rc != 0:
            self.fail_json(
                msg="Unable to tag the file {0} to {1}".format(file_path, tag),
                stdout=out, stderr=err, rc=rc,
                stdout_lines=out.splitlines(),
                stderr_lines=err.splitlines()
            )

    def _run_mvs_command(self, pgm, cmd, dd=None, authorized=False):
        """Run a particular MVS command.

        Arguments:
            pgm {str} -- The MVS program to run
            cmd {str} -- The input command to pass to the program

        Keyword Arguments:
            dd {dict} -- The DD definitions required by the program. (Default {None})
            authorized {bool} -- Indicates whether the MVS program should run
            as authorized. (Default {False})

        Returns:
            tuple[int, str, str] -- A tuple of return code, stdout and stderr
        """
        sysprint = "sysprint"
        sysin = "sysin"
        pgm = pgm.upper()
        if pgm == "IKJEFT01":
            sysprint = "systsprt"
            sysin = "systsin"

        mvs_cmd = "mvscmd"
        if authorized:
            mvs_cmd += "auth"
        mvs_cmd += " --pgm={0} --{1}=* --{2}=stdin"
        if dd:
            for k, v in dd.items():
                mvs_cmd += " --{0}={1}".format(k, v)

        return self.run_command(
            mvs_cmd.format(pgm, sysprint, sysin), data=cmd
        )


class USSCopyHandler(CopyHandler):
    def __init__(self, module, dest_exists, is_binary=False, common_file_args=None):
        """Utility class to handle copying files or data sets to USS target

        Arguments:
            module {AnsibleModule} -- The AnsibleModule object from currently running module
            dest_exists {boolean} -- Whether destination already exists

        Keyword Arguments:
            common_file_args {dict} -- mode, group and owner information to be
            applied to destination file.

            is_binary {bool} -- Whether the file to be copied contains binary data
        """
        super().__init__(module, dest_exists, is_binary=is_binary)
        self.common_file_args = common_file_args

    def copy_to_uss(self, conv_path, temp_path, src_ds_type, src_member, member_name):
        """Copy a file or data set to a USS location

        Arguments:
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source file or directory
            src_ds_type {str} -- Type of source
            src_member {bool} -- Whether src is a data set member
            member_name {str} -- The name of the source data set member

        Returns:
            {str} -- Destination where the file was copied to
        """
        src = self.module.params.get("src")
        dest = self.module.params.get("dest")
        if src_ds_type in MVS_SEQ.union(MVS_PARTITIONED):
            self._mvs_copy_to_uss(src, dest, src_ds_type, src_member, member_name=member_name)
        else:
            if os.path.isfile(temp_path or conv_path or src):
                dest = self._copy_to_file(src, dest, conv_path, temp_path)
            else:
                dest = self._copy_to_dir(src, dest, conv_path, temp_path)

        if self.common_file_args is not None:
            mode = self.common_file_args.get("mode")
            group = self.common_file_args.get("group")
            owner = self.common_file_args.get("owner")
            if mode is not None:
                self.module.set_mode_if_different(dest, mode, False)
            if group is not None:
                self.module.set_group_if_different(dest, group, False)
            if owner is not None:
                self.module.set_owner_if_different(dest, owner, False)
        return dest

    def _copy_to_file(self, src, dest, conv_path, temp_path):
        """Helper function to copy a USS src to USS dest.

        Arguments:
            src {str} -- USS source file path
            dest {str} -- USS dest file path
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source file or directory

        Returns:
            {str} -- Destination where the file was copied to
        """
        if os.path.isdir(dest):
            dest = os.path.join(dest, os.path.basename(src) if src else 'inline_copy')

        src = temp_path or conv_path or src
        try:
            if self.is_binary:
                copy.copy_uss2uss_binary(src, dest)
            else:
                shutil.copy(src, dest)
        except OSError as err:
            self.fail_json(
                msg="Destination {0} is not writable".format(dest),
                stderr=str(err)
            )
        except Exception as err:
            self.fail_json(
                msg="Unable to copy file {0} to {1}".format(src, dest),
                stderr=str(err)
            )
        return dest

    def _copy_to_dir(self, src_dir, dest_dir, conv_path, temp_path):
        """Helper function to copy a USS directory to another USS directory

        Arguments:
            src_dir {str} -- USS source directory
            dest {str} -- USS dest directory
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source directory

        Returns:
            {str} -- Destination where the directory was copied to
        """
        src_dir = temp_path or conv_path or src_dir
        if os.path.exists(dest_dir):
            try:
                shutil.rmtree(dest_dir)
            except Exception as err:
                self.fail_json(
                    msg="Unable to delete pre-existing directory {0}".format(dest_dir),
                    stdout=str(err)
                )
        try:
            shutil.copytree(src_dir, dest_dir)
        except Exception as err:
            self.fail_json(
                msg="Error while copying data to destination directory {0}".format(dest_dir),
                stdout=str(err)
            )
        return dest_dir

    def _mvs_copy_to_uss(self, src, dest, src_ds_type, src_member, member_name=None):
        """Helper function to copy an MVS data set src to USS dest.

        Arguments:
            src {str} -- Name of source data set or data set member
            dest {str} -- USS dest file path
            src_ds_type -- Type of source
            src_member {bool} -- Whether src is a data set member

        Keyword Arguments:
            member_name {str} -- The name of the source data set member
        """
        if os.path.isdir(dest):
            # If source is a data set member, destination file should have
            # the same name as the member.
            dest = "{0}/{1}".format(dest, member_name or src)

            if src_ds_type in MVS_PARTITIONED and not src_member:
                try:
                    os.mkdir(dest)
                except FileExistsError:
                    pass
        try:
            if src_ds_type in MVS_SEQ:
                copy.copy_ps2uss(src, dest, is_binary=self.is_binary)
            else:
                copy.copy_pds2uss(src, dest, is_binary=self.is_binary)
        except Exception as err:
            self.fail_json(msg=str(err))


class PDSECopyHandler(CopyHandler):
    def __init__(self, module, dest_exists, is_binary=False):
        """ Utility class to handle copying to partitioned data sets or
        partitioned data set members.

        Arguments:
            module {AnsibleModule} -- The AnsibleModule object from currently running module
            dest_exists {boolean} -- Whether destination already exists

        Keyword Arguments:
            is_binary {bool} -- Whether the data set to be copied contains binary data
        """
        super().__init__(module, dest_exists, is_binary=is_binary)

    def copy_to_pdse(self, src, temp_path, conv_path, dest, src_ds_type):
        """Copy source to a PDS/PDSE or PDS/PDSE member.

        Arguments:
            src {str} -- Path to USS file/directory or data set name.
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source file/directory
            dest {str} -- Name of destination data set
            src_ds_type {str} -- The type of source
        """
        src = temp_path or conv_path or src
        if src_ds_type == "USS":
            if self.dest_exists:
                self._delete_members(dest)
            path, dirs, files = next(os.walk(src))
            for file in files:
                member_name = file[:file.rfind('.')] if '.' in file else file
                full_file_path = path + "/" + file
                try:
                    copy.copy_uss2mvs(
                        full_file_path, "{0}({1})".format(dest, member_name),
                        "PO", is_binary=self.is_binary
                    )
                except Exception as err:
                    self.fail_json(msg=str(err))
        else:
            if self.dest_exists:
                temp_ds = Datasets.temp_name()
                Datasets.move(dest, temp_ds)
                self.allocate_model(dest, src)
                Datasets.delete(temp_ds)
            dds = dict(OUTPUT=dest, INPUT=src)
            copy_cmd = "   COPY OUTDD=OUTPUT,INDD=((INPUT,R))"
            rc, out, err = self._run_mvs_command("IEBCOPY", copy_cmd, dds)
            if rc != 0:
                self.fail_json(
                    msg="IEBCOPY encountered a problem while copying {0} to {1}".format(src, dest),
                    stdout=out, stderr=err, rc=rc,
                    stdout_lines=out.splitlines(),
                    stderr_lines=err.splitlines(),
                    cmd=copy_cmd
                )

    def copy_to_member(self, src, temp_path, conv_path, dest, copy_member=False):
        """Copy source to a PDS/PDSE member. The only valid sources are:
            - USS files
            - Sequential data sets
            - PDS/PDSE members
            - local files

        Arguments:
            src {str} -- Path to USS file or data set name.
            temp_path {str} -- Path to the location where the control node transferred data to
            conv_path {str} -- Path to the converted source file/directory
            dest {str} -- Name of destination data set

        Keyword Arguments:
            copy_member {bool} -- Whether destination specifies a member name. (default {False})

        Returns:
            {str} -- Destination where the member was copied to
        """
        if src and '/' in src and not copy_member:
            dest = "{0}({1})".format(dest, os.path.basename(src))

        src = temp_path or conv_path or src
        if '/' in src:
            try:
                copy.copy_uss2mvs(src, dest, "PO", is_binary=self.is_binary)
            except Exception as err:
                self.fail_json(msg=str(err))
        else:
            rc = Datasets.copy(src, dest)
            if rc != 0:
                self.fail_json(
                    msg="Unable to copy to data set member {}".format(dest),
                    rc=rc
                )
        return dest

    def create_pdse(
        self, src, dest_name, size, src_ds_type, remote_src=False, vol=None
    ):
        """Create a partitiomned data set specified by 'dest_name'

        Arguments:
            src {str} -- Name of the source data set
            dest_name {str} -- Name of the data set to be created
            size {int} -- The size, in bytes, of the source file
            dest_ds_type {str} -- Type of the data set to be created
            src_ds_type {str} -- Type of source data set

        Keyword Arguments:
            remote_src {bool} -- Whether source is located on remote system. (Default {False})
            vol {str} -- Volume where source data set is stored. (Default {None})
        """
        rc = out = err = None
        if remote_src:
            if src_ds_type in MVS_PARTITIONED:
                rc = self.allocate_model(dest_name, src)
            elif src_ds_type in MVS_SEQ:
                rc = self._allocate_pdse(dest_name, vol=vol, src=src)
            elif os.path.isfile(src):
                size = Path(src).stat().st_size
                rc = self._allocate_pdse(dest_name, size=size)
            elif os.path.isdir(src):
                path, dirs, files = next(os.walk(src))
                if dirs:
                    self.fail_json(
                        msg="Subdirectory found in source directory {0}".format(src)
                    )
                size = sum(Path(path + "/" + f).stat().st_size for f in files)
                rc = self._allocate_pdse(dest_name, size=size)
        else:
            rc = self._allocate_pdse(dest_name, size=size)
        if rc != 0:
            self.fail_json(
                msg="Unable to allocate destination data set to copy {0}".format(src),
                stdout=out, stderr=err, rc=rc,
                stdout_lines=out.splitlines() if out else None,
                stderr_lines=err.splitlines() if err else None
            )

    def _allocate_pdse(self, ds_name, size=None, vol=None, src=None):
        """Allocate a partitioned extended data set. If 'size'
        is provided, allocate PDSE using this given size. If neither of them
        are provided, obtain the 'src' data set size from vtoc and allocate using
        that information.

        Arguments:
            ds_name {str} -- The name of the PDSE to allocate

        Keyword Arguments:
            size {int} -- The size, in bytes, of the allocated PDSE
            src {str} -- The name of the source data set from which to get the size
            vol {str} -- Volume of the source data set
        """
        recfm = "FB"
        lrecl = 80
        default_size = 5242880   # Use the default 5 Megabytes
        if size is None:
            if vol:
                ds_vtoc = vtoc.VolumeTableOfContents(self.module)
                vtoc_info = ds_vtoc.get_data_set_entry(src, vol)
                tracks = int(vtoc_info.get("last_block_pointer").get("track"))
                blocks = int(vtoc_info.get("last_block_pointer").get("block"))
                blksize = int(vtoc_info.get("block_size"))
                bytes_per_trk = 56664
                size = (tracks * bytes_per_trk) + (blocks * blksize)
                recfm = vtoc_info.get("record_format") or recfm
                lrecl = int(vtoc_info.get("record_length")) or lrecl
            else:
                size = default_size

        size = "{0}K".format(str(int(math.ceil(size/1024))))
        return Datasets.create(ds_name, "PDSE", size, recfm, "", lrecl)

    def _delete_members(self, data_set):
        """Delete all members from a partitioned data set.

        Arguments:
            data_set {str} -- Name of the PDS/PDSE
        """
        members = Datasets.list_members(data_set + "(*)")
        if members:
            try:
                for m in members.split('\n'):
                    rc, out, err = self.run_command("mrm {0}({1})".format(data_set, m))
                    if rc != 0:
                        self.fail_json(
                            msg="Unable to delete data set member {0} from {1}".format(m, data_set),
                            rc=rc, out=out, err=err
                        )
            finally:
                self.run_command("rm /tmp/mrm.*.sysprint")


class CopyUtil(object):

    @staticmethod
    def is_compatible(src_type, dest_type, copy_member, src_member):
        """Determine whether the src and dest are compatible and src can be
        copied to dest.

        Arguments:
            src_type {str} -- Type of the source (e.g. PDSE, USS)
            dest_type {str} -- Type of destination
            src_member {bool} -- Whether src is a data set member
            copy_member {bool} -- Whether dest is a data set member

        Returns:
            {bool} -- Whether src can be copied to dest
        """
        # ********************************************************************
        # If the destination does not exist, then obviously it will need
        # to be created. As a result, target is compatible.
        # ********************************************************************
        if dest_type is None:
            return True

        # ********************************************************************
        # If source is a sequential data set, then destination must be
        # partitioned data set member, other sequential data sets or USS files.
        # Anything else is incompatible.
        # ********************************************************************
        if src_type in MVS_SEQ:
            return not (
                (dest_type in MVS_PARTITIONED and not copy_member) or
                dest_type == "VSAM"
            )

        # ********************************************************************
        # If source is a partitioned data set, then we need to determine
        # target compatibility for two different scenarios:
        #   - If the source is a data set member
        #   - If the source is an entire data set
        #
        # In the first case, the possible targets are: USS files, PDS/PDSE
        # members and sequential data sets. Anything else is incompatible.
        #
        # In the second case, the possible targets are USS directories and
        # other PDS/PDSE. Anything else is incompatible.
        # ********************************************************************
        elif src_type in MVS_PARTITIONED:
            if dest_type == "VSAM":
                return False
            if not src_member:
                return not (
                    copy_member or dest_type in MVS_SEQ
                )
            return True

        elif src_type == "USS":
            return dest_type != "VSAM"

        else:
            return dest_type == "VSAM"

    @staticmethod
    def get_file_checksum(src):
        """Calculate SHA256 hash for a given file

        Arguments:
            src {str} -- The absolute path of the file

        Returns:
            str -- The SHA256 hash of the contents of input file
        """
        b_src = to_bytes(src)
        if not os.path.exists(b_src) or os.path.isdir(b_src):
            return None
        blksize = 64 * 1024
        hash_digest = sha256()
        try:
            with open(to_bytes(src, errors='surrogate_or_strict'), 'rb') as infile:
                block = infile.read(blksize)
                while block:
                    hash_digest.update(block)
                    block = infile.read(blksize)
        except Exception as err:
            raise
        return hash_digest.hexdigest()

    @staticmethod
    def extract_dsname(data_set):
        """Extract the actual name of the data set from a given input source

        Arguments:
            data_set {str} -- Input data set name

        Returns:
            {str} -- The actual name of the data set
        """
        result = ""
        for c in data_set:
            if c == '(':
                break
            result += c
        return result

    @staticmethod
    def extract_member_name(data_set):
        """Extract the member name from a given input source

        Arguments:
            data_set {str} -- Input source name

        Returns:
            {str} -- The member name
        """
        start = data_set.find('(')
        member = ""
        for i in range(start+1, len(data_set)):
            if data_set[i] == ')':
                break
            member += data_set[i]
        return member

    @staticmethod
    def cleanup(src):
        """Remove the file or directory specified by path

        Arguments:
            src {str} -- The absolute path to the file or directory
        """
        if src and os.path.exists(src):
            if os.path.isdir(src):
                shutil.rmtree(src)
            else:
                os.remove(src)


def run_module():
    module = AnsibleModule(
        argument_spec=dict(
            src=dict(type='str'),
            dest=dict(required=True, type='str'),
            is_binary=dict(type='bool', default=False),
            encoding=dict(type='dict'),
            content=dict(type='str', no_log=True),
            backup=dict(type='bool', default=False),
            backup_path=dict(type='str'),
            local_follow=dict(type='bool'),
            force=dict(type='bool', default=True),
            remote_src=dict(type='bool', default=False),
            validate=dict(type='bool'),
            is_uss=dict(type='bool'),
            is_pds=dict(type='bool'),
            is_mvs_dest=dict(type='bool'),
            size=dict(type='int'),
            temp_path=dict(type='str'),
            copy_member=dict(type='bool'),
            src_member=dict(type='bool')
        ),
        add_file_common_args=True
    )

    arg_def = dict(
        src=dict(arg_type='data_set_or_path', required=False),
        dest=dict(arg_type='data_set_or_path', required=True),
        is_binary=dict(arg_type='bool', required=False, default=False),
        content=dict(arg_type='str', required=False),
        backup=dict(arg_type='bool', default=False, required=False),
        backup_path=dict(arg_type='data_set_or_path', required=False),
        force=dict(arg_type='bool', default=True, required=False),
        local_follow=dict(arg_type='bool', default=True, required=False),
        remote_src=dict(arg_type='bool', default=False, required=False),
        checksum=dict(arg_type='str', required=False),
        validate=dict(arg_type='bool', required=False)
    )

    if module.params.get("encoding"):
        module.params.update(dict(
            from_encoding=module.params.get('encoding').get('from'),
            to_encoding=module.params.get('encoding').get('to'))
        )
        arg_def.update(dict(
            from_encoding=dict(arg_type='encoding'),
            to_encoding=dict(arg_type='encoding')
        ))

    try:

        # ********************************************************************
        # Verify the validity of module args. BetterArgParser raises ValueError
        # when a parameter fails its validation check
        # ********************************************************************
        try:
            parser = better_arg_parser.BetterArgParser(arg_def)
            parsed_args = parser.parse_args(module.params)
        except ValueError as err:
            module.fail_json(
                msg="Parameter verification failed", stderr=str(err)
            )

        # ------------------------------- o -----------------------------------

        src = parsed_args.get('src')
        b_src = to_bytes(src, errors='surrogate_or_strict')
        dest = parsed_args.get('dest')
        b_dest = to_bytes(dest, errors='surrogate_or_strict')
        remote_src = parsed_args.get('remote_src')
        is_binary = parsed_args.get('is_binary')
        content = parsed_args.get('content')
        force = parsed_args.get('force')
        backup = parsed_args.get('backup')
        backup_path = parsed_args.get('backup_path')
        validate = parsed_args.get('validate')
        mode = module.params.get('mode')
        group = module.params.get('group')
        owner = module.params.get('owner')
        encoding = module.params.get('encoding')
        is_uss = module.params.get('is_uss')
        is_pds = module.params.get('is_pds')
        is_mvs_dest = module.params.get('is_mvs_dest')
        temp_path = module.params.get('temp_path')
        alloc_size = module.params.get('size')
        src_member = module.params.get('src_member')
        copy_member = module.params.get('copy_member')

        # ********************************************************************
        # When copying to and from a data set member, 'dest' or 'src' will be
        # in the form DATA.SET.NAME(MEMBER). When this is the case, extract the
        # actual name of the data set.
        # ********************************************************************
        dest_name = CopyUtil.extract_dsname(dest)
        src_name = CopyUtil.extract_dsname(src) if src else None
        member_name = CopyUtil.extract_member_name(src) if src_member else None

        conv_path = None
        src_ds_vol = None
        res_args = dict()

        # ********************************************************************
        # 1. When the source is a USS file or directory , verify that the file
        #    or directory exists and has proper read permissions.
        # 2. Capture the file or data sets mode bits when mode param is set
        #    to 'preserve'
        # ********************************************************************
        if remote_src and '/' in src:
            if not os.path.exists(b_src):
                module.fail_json(msg="Source {0} does not exist".format(src))
            if not os.access(src, os.R_OK):
                module.fail_json(msg="Source {0} is not readable".format(src))
            if mode == 'preserve':
                mode = '0{:o}'.format(stat.S_IMODE(os.stat(b_src).st_mode))

        # ********************************************************************
        # 1. Use DataSetUtils to determine the src and dest data set type.
        # 2. For source data sets, find its volume, which will be used later.
        # ********************************************************************
        try:
            if is_uss:
                dest_ds_type = "USS"
                dest_exists = os.path.exists(dest)
            else:
                dest_du = data_set.DataSetUtils(dest_name)
                dest_exists = dest_du.exists()
                dest_ds_type = dest_du.ds_type()
            if temp_path or '/' in src:
                src_ds_type = "USS"
            else:
                src_du = data_set.DataSetUtils(src_name)
                if src_du.exists():
                    if src_member and not src_du.member_exists(member_name):
                        raise NonExistentSourceError(src)
                    src_ds_type = src_du.ds_type()
                    src_ds_vol = src_du.volume()
                else:
                    raise NonExistentSourceError(src)

        except Exception as err:
            module.fail_json(msg=str(err))

        # ********************************************************************
        # Some src and dest combinations are incompatible. For example, it is
        # not possible to copy a PDS member to a VSAM data set or a USS file
        # to a PDS. Perform these sanity checks.
        # ********************************************************************
        if not CopyUtil.is_compatible(
            src_ds_type, dest_ds_type, copy_member, src_member
        ):
            module.fail_json(
                msg="Incompatible target type '{0}' for source '{1}'".format(
                    dest_ds_type, src_ds_type
                )
            )

        # ********************************************************************
        # Backup should only be performed if dest is an existing file or
        # data set. Otherwise ignored.
        #
        # If destination exists and the 'force' parameter is set to false,
        # the module exits with a note to the user.
        # ********************************************************************
        copy_handler = CopyHandler(module, dest_exists, is_binary=is_binary)
        if dest_exists:
            if not force:
                module.exit_json(note="Destination exists. No data was copied")

            if backup or backup_path:
                backup_path = copy_handler.backup_data(
                    dest_name, dest_ds_type, backup_path
                )
        # ********************************************************************
        # If destination does not exist, it must be created. To determine
        # what type of data set destination must be, a couple of simple checks
        # can be done. For example:
        # 1. Destination must be a PDS/PDSE if:
        #   - The source is a local directory
        #   - The source is a USS directory
        #   - The source is a PDS/PDSE
        #   - The destination is in the form DATA.SET.NAME(MEMBER)
        #
        # USS files and sequential data sets are not required to be explicitly
        # created; they are automatically created by the Python/ZOAU API.
        # ********************************************************************
        else:
            if not dest_ds_type:
                if(
                    is_pds or
                    copy_member or
                    (src_ds_type in MVS_PARTITIONED and (not src_member) and is_mvs_dest) or
                    (os.path.isdir(b_src) and is_mvs_dest)
                ):
                    dest_ds_type = "PDSE"
                    PDSECopyHandler(module, dest_exists).create_pdse(
                        src, dest_name, alloc_size, src_ds_type, remote_src=remote_src,
                        vol=src_ds_vol
                    )
                elif src_ds_type == "VSAM":
                    dest_ds_type = "VSAM"
                elif not is_uss:
                    dest_ds_type = "SEQ"

            res_args['changed'] = True

        # ********************************************************************
        # Encoding conversion is only valid if the source is a local file,
        # local directory or a USS file/directory.
        # ********************************************************************
        if encoding:
            if remote_src and src_ds_type != "USS":
                copy_handler.fail_json(
                    msg="Encoding conversion is only valid for USS source"
                )
            # 'conv_path' points to the converted src file or directory
            conv_path = copy_handler.convert_encoding(src, temp_path, encoding)

        # ------------------------------- o -----------------------------------
        # Copy to USS file or directory
        # ---------------------------------------------------------------------
        if is_uss:
            if dest_exists and not os.access(dest, os.W_OK):
                copy_handler.fail_json(
                    msg="Destination {0} is not writable".format(dest)
                )

            uss_copy_handler = USSCopyHandler(
                module, dest_exists, is_binary=is_binary,
                common_file_args=dict(mode=mode, group=group, owner=owner)
            )
            dest = uss_copy_handler.copy_to_uss(
                conv_path, temp_path, src_ds_type, src_member, member_name
            )
            res_args['size'] = Path(dest).stat().st_size
            if validate:
                try:
                    remote_checksum = CopyUtil.get_file_checksum(temp_path or src)
                    dest_checksum = CopyUtil.get_file_checksum(dest)
                except Exception as err:
                    copy_handler.fail_json(
                        msg="Unable to calculate checksum", stderr=str(err)
                    )
                res_args['checksum'] = remote_checksum
                res_args['changed'] = (
                    res_args.get("changed") or remote_checksum != dest_checksum
                )

        # ------------------------------- o -----------------------------------
        # Copy to sequential data set
        # ---------------------------------------------------------------------
        elif dest_ds_type in MVS_SEQ:
            copy_handler.copy_to_seq(src, temp_path, conv_path, dest, src_ds_type)

        # ------------------------------- o -----------------------------------
        # Copy to PDS/PDSE
        # ---------------------------------------------------------------------
        elif dest_ds_type in MVS_PARTITIONED:
            if not remote_src and not copy_member and os.path.isdir(temp_path):
                temp_path = os.path.join(temp_path, os.path.basename(src))

            pdse_copy_handler = PDSECopyHandler(module, dest_exists, is_binary=is_binary)
            if copy_member or os.path.isfile(temp_path or src) or src_member:
                dest = pdse_copy_handler.copy_to_member(
                    src, temp_path, conv_path, dest, copy_member=copy_member
                )
            else:
                pdse_copy_handler.copy_to_pdse(
                    src, temp_path, conv_path, dest, src_ds_type
                )

        # ------------------------------- o -----------------------------------
        # Copy to VSAM data set
        # ---------------------------------------------------------------------
        else:
            copy_handler.copy_to_vsam(src, dest)

    finally:
        CopyUtil.cleanup(module.params.get("temp_path"))
        CopyUtil.cleanup(conv_path)

    res_args.update(
        dict(
            src=src,
            dest=dest,
            ds_type=dest_ds_type,
            dest_exists=dest_exists,
            backup_file=backup_path
        )
    )
    module.exit_json(**res_args)


class EncodingConversionError(Exception):
    def __init__(self, src, f_code, t_code):
        self.msg = "Unable to convert encoding for {0} from {1} to {2}".format(src, f_code, t_code)
        super().__init__(self.msg)


class NonExistentSourceError(Exception):
    def __init__(self, src):
        self.msg = "Source {0} does not exist".format(src)
        super().__init__(self.msg)


def main():
    run_module()


if __name__ == '__main__':
    main()
